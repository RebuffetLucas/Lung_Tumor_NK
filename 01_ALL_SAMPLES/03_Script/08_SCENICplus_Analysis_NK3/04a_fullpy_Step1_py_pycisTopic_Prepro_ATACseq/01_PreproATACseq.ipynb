{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Step1: Using PycisTopic to preprocess scATAC data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pycisTopic\n",
    "pycisTopic.__version__\n",
    "import subprocess\n",
    "from pycisTopic.cistopic_class import *\n",
    "from pycisTopic.utils import *\n",
    "from pycisTopic.lda_models import * \n",
    "import anndata as ad\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Load Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Determine the folder in which the code is executed\n",
    "WORKING_DIR = os.getcwd()\n",
    "sys.path.append(os.path.abspath( WORKING_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%run -i ../../globalParams.py #GlobalParams\n",
    "%run -i ../../sampleParams.py #sampleParams\n",
    "%run -i ./analysisParams.py #AnalysisParams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out_dir = PATH_ANALYSIS_OUTPUT\n",
    "os.makedirs(out_dir, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the dictionnary of fragments from the fragment directory:\n",
    "file_list = os.listdir(PATH_TO_FRAGMENTS_FILES)\n",
    "\n",
    "# Filter out the .gz files but exclude .gz.tbi files\n",
    "gz_files = [f for f in file_list if f.endswith('.gz') and not f.endswith('.gz.tbi')]\n",
    "\n",
    "# Create the fragments_dict with keys based on the sample identifiers\n",
    "fragments_dict = {f.split('_')[0].replace('-', ''): os.path.join(PATH_TO_FRAGMENTS_FILES, f) for f in gz_files}\n",
    "\n",
    "# Print the resulting dictionary\n",
    "fragments_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Getting pseudobulk profiles from cell annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#read the barcode to cell type annotation\n",
    "import pandas as pd\n",
    "cell_data = pd.read_csv(PATH_TO_CELLDATA_CSV,index_col=0)\n",
    "\n",
    "#Add columns sample_id and barcodes\n",
    "cell_data['sample_id'] = cell_data['sample']\n",
    "cell_data['barcode'] = cell_data.index.str.split('_').str[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Rename fragments_dict to have the right names\n",
    "# Create a mapping from the existing keys in fragments_dict to the sample_id in cell_data\n",
    "sample_mapping = dict(cell_data[['sample', 'orig.ident']].drop_duplicates().values)\n",
    "# Reverse the mapping to use sample as keys(since they correspond to the current keys in fragments_dict)\n",
    "sample_mapping = {v.replace('-', ''): k for k, v in sample_mapping.items()}\n",
    "# Create a new dictionary with the updated keys\n",
    "fragments_dict = {sample_mapping.get(k, k): v for k, v in fragments_dict.items()}\n",
    "\n",
    "# Print the new dictionary to verify\n",
    "fragments_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Download the chromosome size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chromsizes = pd.read_table(\n",
    "    \"http://hgdownload.cse.ucsc.edu/goldenPath/hg38/bigZips/hg38.chrom.sizes\",\n",
    "    header = None,\n",
    "    names = [\"Chromosome\", \"End\"]\n",
    ")\n",
    "chromsizes.insert(1, \"Start\", 0)\n",
    "chromsizes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "## Generate Pseudobulk ATAC-seq profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.pseudobulk_peak_calling import export_pseudobulk\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, \"consensus_peak_calling\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(out_dir, \"consensus_peak_calling/pseudobulk_bed_files\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(out_dir, \"consensus_peak_calling/pseudobulk_bw_files\"), exist_ok = True)\n",
    "\n",
    "\n",
    "bw_paths, bed_paths = export_pseudobulk(\n",
    "    input_data = cell_data,\n",
    "    variable = CELL_TYPE_COLNAME,\n",
    "    sample_id_col = SAMPLE_ID_COLNAME,\n",
    "    chromsizes = chromsizes,\n",
    "    bed_path = os.path.join(out_dir, \"consensus_peak_calling/pseudobulk_bed_files\"),\n",
    "    bigwig_path = os.path.join(out_dir, \"consensus_peak_calling/pseudobulk_bw_files\"),\n",
    "    path_to_fragments = fragments_dict,\n",
    "    n_cpu = 22,\n",
    "    normalize_bigwig = True,\n",
    "    temp_dir = \"/tmp\",\n",
    "    split_pattern = \"_\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the paths to the disk\n",
    "with open(os.path.join(out_dir, \"consensus_peak_calling/bw_paths.tsv\"), \"wt\") as f:\n",
    "    for v in bw_paths:\n",
    "        _ = f.write(f\"{v}\\t{bw_paths[v]}\\n\")\n",
    "with open(os.path.join(out_dir, \"consensus_peak_calling/bed_paths.tsv\"), \"wt\") as f:\n",
    "    for v in bed_paths:\n",
    "        _ = f.write(f\"{v}\\t{bed_paths[v]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## Infering consensus peaks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "### Peak calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_paths = {}\n",
    "with open(os.path.join(out_dir, \"consensus_peak_calling/bw_paths.tsv\")) as f:\n",
    "    for line in f:\n",
    "        v, p = line.strip().split(\"\\t\")\n",
    "        bw_paths.update({v: p})\n",
    "\n",
    "bed_paths = {}\n",
    "with open(os.path.join(out_dir, \"consensus_peak_calling/bed_paths.tsv\")) as f:\n",
    "    for line in f:\n",
    "        v, p = line.strip().split(\"\\t\")\n",
    "        bed_paths.update({v: p})\n",
    "\n",
    "\n",
    "from pycisTopic.pseudobulk_peak_calling import peak_calling\n",
    "macs_path = \"macs2\"\n",
    "\n",
    "os.makedirs(os.path.join(out_dir, \"consensus_peak_calling/MACS\"), exist_ok = True)\n",
    "\n",
    "narrow_peak_dict = peak_calling(\n",
    "    macs_path = macs_path,\n",
    "    bed_paths = bed_paths,\n",
    "    outdir = os.path.join(os.path.join(out_dir, \"consensus_peak_calling/MACS\")),\n",
    "    genome_size = 'hs',\n",
    "    n_cpu = 10,\n",
    "    input_format = 'BEDPE',\n",
    "    shift = 73,\n",
    "    ext_size = 146,\n",
    "    keep_dup = 'all',\n",
    "    q_value = 0.05,\n",
    "    #_temp_dir = '/scratch/leuven/330/vsc33053/ray_spill'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "### Derive the consensus peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.iterative_peak_calling import get_consensus_peaks\n",
    "# Other param\n",
    "peak_half_width=250\n",
    "path_to_blacklist=PATH_TO_BLACK_LIST\n",
    "# Get consensus peaks\n",
    "consensus_peaks = get_consensus_peaks(\n",
    "    narrow_peaks_dict = narrow_peak_dict,\n",
    "    peak_half_width = peak_half_width,\n",
    "    chromsizes = chromsizes,\n",
    "    path_to_blacklist = path_to_blacklist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_peaks.to_bed(\n",
    "    path = os.path.join(out_dir, \"consensus_peak_calling/consensus_regions.bed\"),\n",
    "    keep =True,\n",
    "    compression = 'infer',\n",
    "    chain = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## QC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "### Download database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This need to adapt the code of docker file (see docker file)\n",
    "!pycistopic tss gene_annotation_list | grep Human\n",
    "\n",
    "!mkdir -p {out_dir}/qc\n",
    "\n",
    "!pycistopic tss get_tss \\\n",
    "    --output {out_dir}/qc/tss.bed \\\n",
    "    --name \"hsapiens_gene_ensembl\" \\\n",
    "    --to-chrom-source ucsc \\\n",
    "    --ucsc hg38"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Calculate QC metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions_bed_filename = os.path.join(out_dir, \"consensus_peak_calling/consensus_regions.bed\")\n",
    "tss_bed_filename = os.path.join(out_dir, \"qc\", \"tss.bed\")\n",
    "\n",
    "pycistopic_qc_commands_filename = \"pycistopic_qc_commands.txt\"\n",
    "\n",
    "# Create text file with all pycistopic qc command lines.\n",
    "with open(pycistopic_qc_commands_filename, \"w\") as fh:\n",
    "    for sample, fragment_filename in fragments_dict.items():\n",
    "        print(\n",
    "            \"pycistopic qc\",\n",
    "            f\"--fragments {fragment_filename}\",\n",
    "            f\"--regions {regions_bed_filename}\",\n",
    "            f\"--tss {tss_bed_filename}\",\n",
    "            f\"--output {os.path.join(out_dir, 'qc')}/{sample}\",\n",
    "            sep=\" \",\n",
    "            file=fh,\n",
    "        )\n",
    "\n",
    "#Then run this in command line or go straight to the next cell for un paralleled process:\n",
    "#cat pycistopic_qc_commands.txt | parallel -j 4 {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Open and read the file line by line\n",
    "with open(pycistopic_qc_commands_filename, \"r\") as file:\n",
    "    for line in file:\n",
    "        # Strip any leading/trailing whitespace\n",
    "        command = line.strip()\n",
    "        \n",
    "        # Skip empty lines\n",
    "        if not command:\n",
    "            continue\n",
    "        \n",
    "        # Execute the command\n",
    "        result = subprocess.run(command, shell=True)\n",
    "        \n",
    "        # Check for errors\n",
    "        if result.returncode != 0:\n",
    "            print(f\"Command failed with return code {result.returncode}: {command}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.plotting.qc_plot import plot_sample_stats, plot_barcode_stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_id in fragments_dict:\n",
    "    fig = plot_sample_stats(\n",
    "        sample_id = sample_id,\n",
    "        pycistopic_qc_output_dir = os.path.join(out_dir, 'qc')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inspect the quality treshold automaticly identified\n",
    "from pycisTopic.qc import get_barcodes_passing_qc_for_sample\n",
    "sample_id_to_barcodes_passing_filters = {}\n",
    "sample_id_to_thresholds = {}\n",
    "for sample_id in fragments_dict:\n",
    "    (\n",
    "        sample_id_to_barcodes_passing_filters[sample_id],\n",
    "        sample_id_to_thresholds[sample_id]\n",
    "    ) = get_barcodes_passing_qc_for_sample(\n",
    "            sample_id = sample_id,\n",
    "            pycistopic_qc_output_dir = os.path.join(out_dir, 'qc'),\n",
    "            unique_fragments_threshold = None, # use automatic thresholding\n",
    "            tss_enrichment_threshold = None, # use automatic thresholding\n",
    "            frip_threshold = 0,\n",
    "            use_automatic_thresholds = True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_id in fragments_dict:\n",
    "    fig = plot_barcode_stats(\n",
    "        sample_id = sample_id,\n",
    "        pycistopic_qc_output_dir = os.path.join(out_dir, 'qc'),\n",
    "        bc_passing_filters = sample_id_to_barcodes_passing_filters[sample_id],\n",
    "        detailed_title = False,\n",
    "        **sample_id_to_thresholds[sample_id]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "### Creating a cis-topic object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_regions = os.path.join(out_dir, \"consensus_peak_calling/consensus_regions.bed\")\n",
    "path_to_blacklist = PATH_TO_BLACK_LIST\n",
    "pycistopic_qc_output_dir = os.path.join(out_dir,\"qc\")\n",
    "#os.makedirs(pycistopic_qc_output_dir, exist_ok = True)\n",
    "\n",
    "from pycisTopic.cistopic_class import create_cistopic_object_from_fragments\n",
    "import polars as pl\n",
    "\n",
    "cistopic_obj_list = []\n",
    "for sample_id in fragments_dict:\n",
    "    sample_metrics = pl.read_parquet(\n",
    "        os.path.join(pycistopic_qc_output_dir, f'{sample_id}.fragments_stats_per_cb.parquet')\n",
    "    ).to_pandas().set_index(\"CB\").loc[ sample_id_to_barcodes_passing_filters[sample_id] ]\n",
    "    cistopic_obj = create_cistopic_object_from_fragments(\n",
    "        path_to_fragments = fragments_dict[sample_id],\n",
    "        path_to_regions = path_to_regions,\n",
    "        path_to_blacklist = path_to_blacklist,\n",
    "        metrics = sample_metrics,\n",
    "        valid_bc = sample_id_to_barcodes_passing_filters[sample_id],\n",
    "        n_cpu = 1,\n",
    "        project = sample_id,\n",
    "        split_pattern = '-'\n",
    "    )\n",
    "    cistopic_obj_list.append(cistopic_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge into one single cisTopic\n",
    "cistopic_obj = merge(cistopic_obj_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "cistopic_obj.cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(\n",
    "    cistopic_obj,\n",
    "    open(os.path.join(out_dir, \"cistopic_obj.pkl\"), \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make cell_data compatible\n",
    "# Split the cell_data index to remove the sample prefix and change the suffix\n",
    "new_index = cell_data.index.to_series().apply(\n",
    "    lambda x: x.split('_')[1] + '-' + cell_data.loc[x, 'sample'] + '___' + cell_data.loc[x, 'sample']\n",
    ")\n",
    "\n",
    "# Update the index of cell_data\n",
    "cell_data.index = new_index\n",
    "\n",
    "# Verify the changes\n",
    "print(cell_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only the cells that are in both cell_data and cistopic object\n",
    "# Ensure the new index is set for cell_data\n",
    "new_index = cell_data.index\n",
    "\n",
    "# Get the index from cistopic_obj\n",
    "cistopic_index = cistopic_obj.cell_data.index\n",
    "\n",
    "# Find the intersection (overlap) between the two indices\n",
    "overlap = new_index.intersection(cistopic_index)\n",
    "\n",
    "# Convert the overlapping indices to a list\n",
    "overlap_list = overlap.to_list()\n",
    "\n",
    "# Subset the cistopic_obj using the `subset` function to keep only cells in overlap\n",
    "cistopic_obj = cistopic_obj.subset(cells=overlap_list, copy=True, split_pattern='___')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_data = cell_data.loc[cell_data.index.isin(overlap)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "### Adding metadata to the cisTopic object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cistopic_obj.add_cell_data(cell_data, split_pattern='_')\n",
    "pickle.dump(\n",
    "    cistopic_obj,\n",
    "    open(os.path.join(out_dir, \"cistopic_obj.pkl\"), \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "cistopic_obj.cell_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "### Running scrublet (Optionnal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "if DO_RUN_SCRUBLET:\n",
    "    import scrublet as scr\n",
    "    scrub = scr.Scrublet(cistopic_obj.fragment_matrix.T, expected_doublet_rate=0.1)\n",
    "    doublet_scores, predicted_doublets = scrub.scrub_doublets()\n",
    "    scrub.plot_histogram();\n",
    "    scrub.call_doublets(threshold=0.22)\n",
    "    scrub.plot_histogram();\n",
    "    scrublet = pd.DataFrame([scrub.doublet_scores_obs_, scrub.predicted_doublets_], columns=cistopic_obj.cell_names, index=['Doublet_scores_fragments', 'Predicted_doublets_fragments']).T\n",
    "    cistopic_obj.add_cell_data(scrublet, split_pattern = '-')\n",
    "    sum(cistopic_obj.cell_data.Predicted_doublets_fragments == True)\n",
    "    pickle.dump(cistopic_obj,open(os.path.join(out_dir, \"cistopic_obj.pkl\"), \"wb\"))\n",
    "    # Remove doublets\n",
    "    singlets = cistopic_obj.cell_data[cistopic_obj.cell_data.Predicted_doublets_fragments == False].index.tolist()\n",
    "    # Subset cisTopic object\n",
    "    cistopic_obj_noDBL = cistopic_obj.subset(singlets, copy=True, split_pattern='-')\n",
    "    print(cistopic_obj_noDBL)\n",
    "    pickle.dump(cistopic_obj,open(os.path.join(out_dir, \"cistopic_obj.pkl\"), \"wb\") )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "## Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel LDA with MALLET\n",
    "\n",
    "import os\n",
    "# Define the path to the tar file and the target directory\n",
    "!wget https://github.com/mimno/Mallet/releases/download/v202108/Mallet-202108-bin.tar.gz\n",
    "\n",
    "# Run the tar command to extract the contents to the specified directory\n",
    "!tar -xf \"Mallet-202108-bin.tar.gz\" -C {PATH_ANALYSIS_OUTPUT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p {PATH_ANALYSIS_OUTPUT}/scratch/leuven/330/vsc33053/ray_spill/mallet/tutorial/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(out_dir)\n",
    "os.environ['MALLET_MEMORY'] = '200G'\n",
    "from pycisTopic.lda_models import run_cgs_models_mallet\n",
    "# Configure paths \n",
    "mallet_path= os.path.join(out_dir, \"Mallet-202108/bin/mallet\")\n",
    "TMP_PATH = os.path.join(out_dir, \"scratch/leuven/330/vsc33053/ray_spill/mallet/tutorial\")\n",
    "SAVE_PATH = os.path.join(out_dir,\"scratch/leuven/330/vsc33053/ray_spill/mallet/tutorial\")\n",
    "\n",
    "!mkdir -p /tmp/scratch/leuven/330/vsc33053/ray_spill/mallet/tutorial/\n",
    "\n",
    "\n",
    "TMP_PATH = os.path.join(\"/tmp\", \"scratch/leuven/330/vsc33053/ray_spill/mallet/tutorial\")\n",
    "#SAVE_PATH = os.path.join(\"/tmp\",\"scratch/leuven/330/vsc33053/ray_spill/mallet/tutorial\")\n",
    "\n",
    "\n",
    "# Run models\n",
    "models=run_cgs_models_mallet(\n",
    "    cistopic_obj,\n",
    "    n_topics=[2, 5, 10, 15, 20, 25, 30, 35, 40, 45, 50],\n",
    "    n_cpu= 40,\n",
    "    n_iter=500,\n",
    "    random_state=555,\n",
    "    alpha=50,\n",
    "    alpha_by_topic=True,\n",
    "    eta=0.1,\n",
    "    eta_by_topic=False,\n",
    "    tmp_path= TMP_PATH,\n",
    "    save_path= SAVE_PATH,\n",
    "    mallet_path= mallet_path,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    models,\n",
    "    open(os.path.join(out_dir, \"models.pkl\"), \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.lda_models import evaluate_models\n",
    "model = evaluate_models(\n",
    "    models,\n",
    "    select_model = 40,\n",
    "    return_model = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "cistopic_obj.add_LDA_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(\n",
    "    cistopic_obj,\n",
    "    open(os.path.join(out_dir, \"cistopic_obj.pkl\"), \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "# Clustering and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.clust_vis import (\n",
    "    find_clusters,\n",
    "    run_umap,\n",
    "    run_tsne,\n",
    "    plot_metadata,\n",
    "    plot_topic,\n",
    "    cell_topic_heatmap\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_clusters(\n",
    "    cistopic_obj,\n",
    "    target  = 'cell',\n",
    "    k = 10,\n",
    "    res = [0.6, 1.2, 3],\n",
    "    prefix = 'pycisTopic_',\n",
    "    scale = True,\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#run_umap(\n",
    "#    cistopic_obj,\n",
    "#    target  = 'cell', scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_tsne(\n",
    "    cistopic_obj,\n",
    "    target  = 'cell', scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting metadata\n",
    "plot_metadata(\n",
    "    cistopic_obj,\n",
    "    reduction_name='tSNE',\n",
    "    variables=['sample_id', 'pycisTopic_leiden_10_0.6', 'pycisTopic_leiden_10_1.2', 'pycisTopic_leiden_10_3'],\n",
    "    target='cell', num_columns=4,\n",
    "    text_size=10,\n",
    "    dot_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ploting continuous values\n",
    "plot_metadata(\n",
    "    cistopic_obj,\n",
    "    reduction_name='tSNE',\n",
    "    variables=['log10_unique_fragments_count', 'tss_enrichment', 'fraction_of_fragments_in_peaks'],\n",
    "    target='cell', num_columns=4,\n",
    "    text_size=10,\n",
    "    dot_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell-topic contribution\n",
    "plot_topic(\n",
    "    cistopic_obj,\n",
    "    reduction_name = 'tSNE',\n",
    "    target = 'cell',\n",
    "    num_columns=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "# Example color dictionary (you can customize this)\n",
    "color_dictionary = {\n",
    "    'seurat_clusters': {cluster: mcolors.to_hex(mcolors.CSS4_COLORS[color]) for cluster, color in zip(sorted(cistopic_obj.cell_data['seurat_clusters'].dropna().unique()), mcolors.CSS4_COLORS)}\n",
    "}\n",
    "\n",
    "\n",
    "# Plot the heatmap with the selected cells\n",
    "cell_topic_heatmap(\n",
    "    cistopic_obj,\n",
    "    variables=['seurat_clusters'],\n",
    "    scale=False,\n",
    "    legend_loc_x=1.0,\n",
    "    legend_loc_y=-1.2,\n",
    "    legend_dist_y=-1,\n",
    "    figsize=(10, 10),\n",
    "    #selected_cells= selected_cells,  # Pass the filtered cells\n",
    "    color_dictionary=color_dictionary \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66",
   "metadata": {},
   "source": [
    "## Topic binarization and QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.topic_binarization import binarize_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_bin_topics_top_3k = binarize_topics(\n",
    "    cistopic_obj, method='ntop', ntop = 3_000,\n",
    "    plot=True, num_columns=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_bin_topics_otsu = binarize_topics(\n",
    "    cistopic_obj, method='otsu',\n",
    "    plot=True, num_columns=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_bin_topics_otsu = binarize_topics(\n",
    "    cistopic_obj, method='otsu',\n",
    "    plot=True, num_columns=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarized_cell_topic = binarize_topics(\n",
    "    cistopic_obj,\n",
    "    target='cell',\n",
    "    method='li',\n",
    "    plot=True,\n",
    "    num_columns=5, nbins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "### Compute the topic quality control metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "#### This step can't be run with R_Cystopic inputs (No model.coherence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.topic_qc import compute_topic_metrics, plot_topic_qc, topic_annotation\n",
    "import matplotlib.pyplot as plt\n",
    "from pycisTopic.utils import fig2img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_qc_metrics = compute_topic_metrics(cistopic_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_dict={}\n",
    "fig_dict['CoherenceVSAssignments']=plot_topic_qc(topic_qc_metrics, var_x='Coherence', var_y='Log10_Assignments', var_color='Gini_index', plot=False, return_fig=True)\n",
    "fig_dict['AssignmentsVSCells_in_bin']=plot_topic_qc(topic_qc_metrics, var_x='Log10_Assignments', var_y='Cells_in_binarized_topic', var_color='Gini_index', plot=False, return_fig=True)\n",
    "fig_dict['CoherenceVSCells_in_bin']=plot_topic_qc(topic_qc_metrics, var_x='Coherence', var_y='Cells_in_binarized_topic', var_color='Gini_index', plot=False, return_fig=True)\n",
    "fig_dict['CoherenceVSRegions_in_bin']=plot_topic_qc(topic_qc_metrics, var_x='Coherence', var_y='Regions_in_binarized_topic', var_color='Gini_index', plot=False, return_fig=True)\n",
    "fig_dict['CoherenceVSMarginal_dist']=plot_topic_qc(topic_qc_metrics, var_x='Coherence', var_y='Marginal_topic_dist', var_color='Gini_index', plot=False, return_fig=True)\n",
    "fig_dict['CoherenceVSGini_index']=plot_topic_qc(topic_qc_metrics, var_x='Coherence', var_y='Gini_index', var_color='Gini_index', plot=False, return_fig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot topic stats in one figure\n",
    "fig=plt.figure(figsize=(40, 43))\n",
    "i = 1\n",
    "for fig_ in fig_dict.keys():\n",
    "    plt.subplot(2, 3, i)\n",
    "    img = fig2img(fig_dict[fig_]) #To convert figures to png to plot together, see .utils.py. This converts the figure to png.\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    i += 1\n",
    "plt.subplots_adjust(wspace=0, hspace=-0.70)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#If needed:\n",
    "#cistopic_obj.cell_data['seurat_clusters'] = cistopic_obj.cell_data['seurat_clusters'].fillna('Not_Assigned')\n",
    "#cistopic_obj.cell_data['seurat_clusters'] = cistopic_obj.cell_data['seurat_clusters'].astype(str)\n",
    "topic_annot = topic_annotation(\n",
    "    cistopic_obj,\n",
    "    annot_var=CELL_TYPE_COLNAME ,\n",
    "    binarized_cell_topic=binarized_cell_topic,\n",
    "    general_topic_thr = 0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "## Differentially Accessible Regions (DARs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.diff_features import (\n",
    "    impute_accessibility,\n",
    "    normalize_scores,\n",
    "    find_highly_variable_features,\n",
    "    find_diff_features\n",
    ")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_acc_obj = impute_accessibility(\n",
    "    cistopic_obj,\n",
    "    selected_cells=None,\n",
    "    selected_regions=None,\n",
    "    scale_factor=10**6\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_imputed_acc_obj = normalize_scores(imputed_acc_obj, scale_factor=10**4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying highly variable DARs (optionnal but speed up the rest of the process)\n",
    "variable_regions = find_highly_variable_features(\n",
    "    normalized_imputed_acc_obj,\n",
    "    min_disp = 0.05,\n",
    "    min_mean = 0.0125,\n",
    "    max_mean = 3,\n",
    "    max_disp = np.inf,\n",
    "    n_bins=20,\n",
    "    n_top_features=None,\n",
    "    plot=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84",
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_PATH = \"/tmp\"\n",
    "markers_dict= find_diff_features(\n",
    "    cistopic_obj,\n",
    "    imputed_acc_obj,\n",
    "    variable= CELL_TYPE_COLNAME,\n",
    "    var_features=variable_regions,\n",
    "    contrasts=None,\n",
    "    adjpval_thr=0.05,\n",
    "    log2fc_thr=np.log2(1.5),\n",
    "    n_cpu=5,\n",
    "    _temp_dir=TMP_PATH,\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.clust_vis import plot_imputed_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_imputed_features(\n",
    "#    cistopic_obj,\n",
    "#    reduction_name='tSNE',\n",
    "#    imputed_data=imputed_acc_obj,\n",
    "#    features=[markers_dict[x].index.tolist()[0] for x in ['9.0', '13.0', '7.0', '30.0']],\n",
    "#    scale=False,\n",
    "#    num_columns=4\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of DARs found:\")\n",
    "print(\"---------------------\")\n",
    "for x in markers_dict:\n",
    "    print(f\"  {x}: {len(markers_dict[x])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "## Save region sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(out_dir, \"region_sets\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(out_dir, \"region_sets\", \"Topics_otsu\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(out_dir, \"region_sets\", \"Topics_top_3k\"), exist_ok = True)\n",
    "os.makedirs(os.path.join(out_dir, \"region_sets\", \"DARs_cell_type\"), exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.utils import region_names_to_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in region_bin_topics_otsu:\n",
    "    region_names_to_coordinates(\n",
    "        region_bin_topics_otsu[topic].index\n",
    "    ).sort_values(\n",
    "        [\"Chromosome\", \"Start\", \"End\"]\n",
    "    ).to_csv(\n",
    "        os.path.join(out_dir, \"region_sets\", \"Topics_otsu\", f\"{topic}.bed\"),\n",
    "        sep = \"\\t\",\n",
    "        header = False, index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in region_bin_topics_top_3k:\n",
    "    region_names_to_coordinates(\n",
    "        region_bin_topics_top_3k[topic].index\n",
    "    ).sort_values(\n",
    "        [\"Chromosome\", \"Start\", \"End\"]\n",
    "    ).to_csv(\n",
    "        os.path.join(out_dir, \"region_sets\", \"Topics_top_3k\", f\"{topic}.bed\"),\n",
    "        sep = \"\\t\",\n",
    "        header = False, index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cell_type in markers_dict:\n",
    "    region_names_to_coordinates(\n",
    "        markers_dict[cell_type].index\n",
    "    ).sort_values(\n",
    "        [\"Chromosome\", \"Start\", \"End\"]\n",
    "    ).to_csv(\n",
    "        os.path.join(out_dir, \"region_sets\", \"DARs_cell_type\", f\"{cell_type}.bed\"),\n",
    "        sep = \"\\t\",\n",
    "        header = False, index = False\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "## Gene Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyranges as pr\n",
    "from pycisTopic.gene_activity import get_gene_activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes = pd.read_table(os.path.join(out_dir, \"qc\", \"hg38.chrom_sizes_and_alias.tsv\"))\n",
    "chromsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes.rename({\"# ucsc\": \"Chromosome\", \"length\": \"End\"}, axis = 1, inplace = True)\n",
    "chromsizes[\"Start\"] = 0\n",
    "chromsizes = pr.PyRanges(chromsizes[[\"Chromosome\", \"Start\", \"End\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98",
   "metadata": {},
   "outputs": [],
   "source": [
    "chromsizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99",
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_annotation = pd.read_table(\n",
    "        os.path.join(out_dir, \"qc\", \"tss.bed\")\n",
    "    ).rename(\n",
    "        {\"Name\": \"Gene\", \"# Chromosome\": \"Chromosome\"}, axis = 1)\n",
    "pr_annotation[\"Transcription_Start_Site\"] = pr_annotation[\"Start\"]\n",
    "pr_annotation = pr.PyRanges(pr_annotation)\n",
    "pr_annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_act, weigths = get_gene_activity(\n",
    "    imputed_acc_obj,\n",
    "    pr_annotation,\n",
    "    chromsizes,\n",
    "    use_gene_boundaries=True, # Whether to use the whole search space or stop when encountering another gene\n",
    "    upstream=[1000, 100000], # Search space upstream. The minimum means that even if there is a gene right next to it\n",
    "                             # these bp will be taken (1kbp here)\n",
    "    downstream=[1000,100000], # Search space downstream\n",
    "    distance_weight=True, # Whether to add a distance weight (an exponential function, the weight will decrease with distance)\n",
    "    decay_rate=1, # Exponent for the distance exponential funciton (the higher the faster will be the decrease)\n",
    "    extend_gene_body_upstream=10000, # Number of bp upstream immune to the distance weight (their value will be maximum for\n",
    "                          #this weight)\n",
    "    extend_gene_body_downstream=500, # Number of bp downstream immune to the distance weight\n",
    "    gene_size_weight=False, # Whether to add a weights based on the length of the gene\n",
    "    gene_size_scale_factor='median', # Dividend to calculate the gene size weigth. Default is the median value of all genes\n",
    "                          #in the genome\n",
    "    remove_promoters=False, # Whether to remove promoters when computing gene activity scores\n",
    "    average_scores=True, # Whether to divide by the total number of region assigned to a gene when calculating the gene\n",
    "                          #activity score\n",
    "    scale_factor=1, # Value to multiply for the final gene activity matrix\n",
    "    extend_tss=[10,10], # Space to consider a promoter\n",
    "    gini_weight = True, # Whether to add a gini index weigth. The more unique the region is, the higher this weight will be\n",
    "    return_weights= True, # Whether to return the final weights\n",
    "    project='Gene_activity') # Project name for the gene activity object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101",
   "metadata": {},
   "outputs": [],
   "source": [
    "DAG_markers_dict= find_diff_features(\n",
    "    cistopic_obj,\n",
    "    gene_act,\n",
    "    variable= CELL_TYPE_COLNAME,\n",
    "    var_features=None,\n",
    "    contrasts=None,\n",
    "    adjpval_thr=0.05,\n",
    "    log2fc_thr=np.log2(1.5),\n",
    "    n_cpu=5,\n",
    "    _temp_dir=TMP_PATH,\n",
    "    split_pattern = '-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_imputed_features(\n",
    "    cistopic_obj,\n",
    "    reduction_name='tSNE',\n",
    "    imputed_data=gene_act,\n",
    "    features=['GATA3', 'TBX21', 'EOMES'], #NK\n",
    "    scale=True,\n",
    "    num_columns=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of DAGs found:\")\n",
    "print(\"---------------------\")\n",
    "for x in markers_dict:\n",
    "    print(f\"  {x}: {len(DAG_markers_dict[x])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Label Transfer (useless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycisTopic.loom import export_region_accessibility_to_loom, export_gene_activity_to_loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-saving the before the loom saving in the PreSave_loom document\n",
    "# Make sure the doc exist \n",
    "os.makedirs(os.path.join(out_dir, \"PreSave_loom\"), exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107",
   "metadata": {},
   "source": [
    "## Pre-Saving for Loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the imputed_acc_obj using pickle\n",
    "pickle.dump(\n",
    "    imputed_acc_obj,\n",
    "    open(os.path.join(out_dir, \"PreSave_loom\", \"imputed_acc_obj.pkl\"), \"wb\")\n",
    ")\n",
    "\n",
    "# Save the cistopic_obj object using pickle\n",
    "pickle.dump(\n",
    "    cistopic_obj,\n",
    "    open(os.path.join(out_dir, \"PreSave_loom\", \"cistopic_obj.pkl\"), \"wb\")\n",
    ")\n",
    "\n",
    "\n",
    "# Save the region_bin_topics_otsu using pickle\n",
    "pickle.dump(\n",
    "    region_bin_topics_otsu,\n",
    "    open(os.path.join(out_dir, \"PreSave_loom\", \"region_bin_topics_otsu.pkl\"), \"wb\")\n",
    ")\n",
    "\n",
    "# Save the binarized_cell_topic using pickle\n",
    "pickle.dump(\n",
    "    binarized_cell_topic,\n",
    "    open(os.path.join(out_dir, \"PreSave_loom\", \"binarized_cell_topic.pkl\"), \"wb\")\n",
    ")\n",
    "\n",
    "# Save the cluster_markers using pickle\n",
    "pickle.dump(\n",
    "    cluster_markers,\n",
    "    open(os.path.join(out_dir, \"PreSave_loom\", \"cluster_markers.pkl\"), \"wb\")\n",
    ")\n",
    "\n",
    "# Save the gene_act using pickle\n",
    "pickle.dump(\n",
    "    gene_act,\n",
    "    open(os.path.join(out_dir, \"PreSave_loom\", \"gene_act.pkl\"), \"wb\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109",
   "metadata": {},
   "source": [
    "## Exporting to Loom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here it may be recommanded to restart kernel and load the saved data before proceeding to the Loom saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.join(out_dir, \"loom\"), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_region_accessibility_to_loom(\n",
    "    accessibility_matrix = imputed_acc_obj,\n",
    "    cistopic_obj = cistopic_obj,\n",
    "    binarized_topic_region = region_bin_topics_otsu,\n",
    "    binarized_cell_topic = binarized_cell_topic,\n",
    "    selected_cells = cistopic_obj.projections['cell']['tSNE'].index.tolist(),\n",
    "    out_fname = os.path.join(out_dir, \"loom\", \"NK_Tumor_MultiSample_pycisTopic_region_accessibility.loom\"),\n",
    "    cluster_annotation = [CELL_TYPE_COLNAME],\n",
    "    cluster_markers = cluster_markers,\n",
    "    tree_structure = ('NK_Tumor_MultiSample', 'pycisTopic', 'noDBL_all'),\n",
    "    title = 'Tutorial - Region accessibility all',\n",
    "    nomenclature = \"hg38\",\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_gene_activity_to_loom(\n",
    "    gene_activity_matrix = gene_act,\n",
    "    cistopic_obj = cistopic_obj,\n",
    "    out_fname = os.path.join(out_dir, \"loom\", \"NK_Tumor_pycisTopic_gene_activity.loom\"),\n",
    "    cluster_annotation = [CELL_TYPE_COLNAME],\n",
    "    cluster_markers = cluster_markers,\n",
    "    tree_structure = ('NK_Tumor_MultiSample', 'pycisTopic', 'ATAC'),\n",
    "    title = 'NK_Tumor - Gene activity',\n",
    "    nomenclature = \"hg38\",\n",
    "    split_pattern = '-'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114",
   "metadata": {},
   "source": [
    "## Stop the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115",
   "metadata": {},
   "outputs": [],
   "source": [
    "if STOP_THE_NOTEBOOK_HERE:\n",
    "  raise Exception(\"Analysis stopped here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correct the cell_data slot to match the cell\n",
    "#Be carefull to the names of the cells in cell_data vs incitopic_obj\n",
    "import pandas as pd\n",
    "cell_data = pd.read_csv(PATH_TO_CELLDATA_CSV, index_col = 0)\n",
    "# print(cell_data)\n",
    "\n",
    "# Split the cell_data index to remove the sample prefix and change the suffix\n",
    "new_index = cell_data.index.to_series().apply(\n",
    "    lambda x: x.split('_')[1] + '-' + cell_data.loc[x, 'sample'] + '___' + cell_data.loc[x, 'sample']\n",
    ")\n",
    "\n",
    "# Update the index of cell_data\n",
    "cell_data.index = new_index\n",
    "\n",
    "# Verify the changes\n",
    "print(cell_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117",
   "metadata": {},
   "source": [
    "## Load the data to go straight to Loom saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pycisTopic\n",
    "pycisTopic.__version__\n",
    "import subprocess\n",
    "from pycisTopic.cistopic_class import *\n",
    "from pycisTopic.utils import *\n",
    "from pycisTopic.lda_models import * \n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Determine the folder in which the code is executed\n",
    "WORKING_DIR = os.getcwd()\n",
    "sys.path.append(os.path.abspath( WORKING_DIR))\n",
    "\n",
    "#Run the basic\n",
    "%run -i ../../globalParams.py #GlobalParams\n",
    "%run -i ../../sampleParams.py #sampleParams\n",
    "%run -i ./analysisParams.py #AnalysisParams\n",
    "\n",
    "#Define outdir\n",
    "out_dir = PATH_ANALYSIS_OUTPUT\n",
    "os.makedirs(out_dir, exist_ok = True)\n",
    "\n",
    "# Load the imputed_acc_obj\n",
    "with open(os.path.join(out_dir, \"PreSave_loom\", \"imputed_acc_obj.pkl\"), \"rb\") as file:\n",
    "    imputed_acc_obj = pickle.load(file)\n",
    "\n",
    "# Load the cistopic_obj\n",
    "with open(os.path.join(out_dir, \"PreSave_loom\", \"cistopic_obj.pkl\"), \"rb\") as file:\n",
    "    cistopic_obj = pickle.load(file)\n",
    "\n",
    "# Load the region_bin_topics_otsu\n",
    "with open(os.path.join(out_dir, \"PreSave_loom\", \"region_bin_topics_otsu.pkl\"), \"rb\") as file:\n",
    "    region_bin_topics_otsu = pickle.load(file)\n",
    "\n",
    "# Load the binarized_cell_topic\n",
    "with open(os.path.join(out_dir, \"PreSave_loom\", \"binarized_cell_topic.pkl\"), \"rb\") as file:\n",
    "    binarized_cell_topic = pickle.load(file)\n",
    "\n",
    "# Load the cluster_markers\n",
    "with open(os.path.join(out_dir, \"PreSave_loom\", \"cluster_markers.pkl\"), \"rb\") as file:\n",
    "    cluster_markers = pickle.load(file)\n",
    "\n",
    "\n",
    "# Load the gene_act\n",
    "with open(os.path.join(out_dir, \"PreSave_loom\", \"gene_act.pkl\"), \"rb\") as file:\n",
    "    gene_act = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119",
   "metadata": {},
   "source": [
    "## Correct the cell data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120",
   "metadata": {},
   "outputs": [],
   "source": [
    "cistopic_obj.cell_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121",
   "metadata": {},
   "outputs": [],
   "source": [
    "markers_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
